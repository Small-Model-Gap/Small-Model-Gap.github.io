<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Small Models Struggle to Learn from Strong Reasoners</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Small Models Struggle to Learn from Strong Reasoners</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://yuetl9.github.io" target="_blank">Yuetai Li</a><sup>1</sup>,</span>
                <span class="author-block">
                  <a href="https://xiangyue9607.github.io/" target="_blank">Xiang Yue</a><sup>2</sup>,</span>
                  <span class="author-block">
                    <a href="https://zhangchenxu.com/" target="_blank">Zhangchen Xu</a><sup>1</sup>,</span>
                    <span class="author-block">
                      <a href="https://fqjiang.work" target="_blank">Fengqing Jiang</a><sup>1</sup>,</span>                  <span class="author-block">
                        <span class="author-block">
                          <a href="https://luyaoniu.github.io/" target="_blank">Luyao Niu</a><sup>1</sup>,</span>
                          <span class="author-block">
                            <a href="https://yuchenlin.xyz/" target="_blank">Bill Yuchen Lin</a><sup>1</sup>,</span>
                            <span class="author-block">
                              <a href="https://www.ece.uw.edu/people/bhaskar-ramasubramanian/" target="_blank">Bhaskar Ramasubramanian</a><sup>3</sup>,</span>
                              <span class="author-block">
                                <a href="https://people.ece.uw.edu/radha/" target="_blank">Radha Poovendran</a><sup>1</sup>
                              </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block"><sup>1</sup>University of Washington</span>
                    <span class="author-block"><sup>2</sup>Carnegie Mellon University</span>
                    <span class="author-block"><sup>3</sup>Western Washington University</span>
                    <!-- <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span> -->
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/2502.12143v1" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                    <span class="link-block">
                      <a href="https://huggingface.co/UWNSL" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon" role="img" aria-label="hugging face">ðŸ¤—</span>
                      <span>Huggingface</span>
                    </a>
                  </span>


                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/Small-Model-Gap/Small-Model-Learnability-Gap" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2502.12143v1" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>




<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Large language models (LLMs) excel in complex reasoning tasks, and distilling their reasoning capabilities into smaller models has shown promise. However, we uncover an interesting phenomenon, which we term the \textit{Small Model Learnability Gap}: small models ($\leq$3B parameters) do not consistently benefit from long chain-of-thought (CoT) reasoning or distillation from larger models. Instead, they perform better when fine-tuned on shorter, simpler reasoning chains that better align with their intrinsic learning capacity.
            <p> 
            <p>
            To address this, we propose Mix Distillation, a simple yet effective strategy that balances reasoning complexity by combining long and short CoT examples or reasoning from both larger and smaller models. Our experiments demonstrate that Mix Distillation significantly improves small model reasoning performance compared to training on either data alone. These findings highlight the limitations of direct strong model distillation and underscore the importance of adapting reasoning complexity for effective reasoning capability transfer.
            </p>
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<section class="section">
  <div class="container is-max-desktop">
    <!-- Optional section title -->
    <div class="has-text-centered">
    <h2 class="title is-3">Small Model Learnability Gap</h2>
    </div>
    <br>
    <!-- Figure on top -->
    <figure class="image" style="width: 60%; margin: 0 auto;">
      <img src="static/images/teaser.png" alt="" />
    </figure>
    <p class="has-text-left">
      Small student models (&leq;3B parameters) do not consistently benefit from long CoT reasoning or distillation from large teacher models. Instead, they perform better when fine-tuned on shorter CoT reasoning or distilled from smaller teachers, which better aligns with their intrinsic learning capacity. We term this phenomenon as the <strong>Small Model Learnability Gap</strong>.
    </p>
    <br>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Optional section title -->
    <div class="has-text-centered">
    <h2 class="title is-3">Main Takeaways</h2>
    </div>
    <br>
    <!-- Figure on top -->
    <p class="has-text-left"></p>
      <strong>Takeaway 1: Long CoT Gap. Small student models tend to benefit more from short CoT, while large student models gain greater advantages from long CoT.</strong> 
    </p>
    <figure class="image">
      <img src="static/images/main_1.jpg" alt="" />
    </figure>
    <p>
        Long CoT Gap (<span>&Delta;<sub>Long</sub>=P<sub>Long</sub> - P<sub>Short</sub></span>) of student models with different model sizes for (a) Qwen family (b) Llama family. For teacher models, <code>QwQ-32B-Preview</code> is chosen to generate long CoT responses, while <code>Qwen2.5-32B-Instruct</code> is chosen to generate short CoT responses. Negative (Positive) <span>&Delta;<sub>Long</sub></span> indicates that long CoT is worse (better) than short CoT. Our results demonstrate that short CoT is better for smaller student models (indicated by <span>&Delta;<sub>Long</sub></span> &lt; 0), while long CoT is better for larger student models (indicated by <span>&Delta;<sub>Long</sub></span> &gt; 0).
      </p>
    <br>


    <p class="has-text-left">
      <strong>Takeaway 2: Large Teacher CoT Gap. Small student models tend to learn better from small teachers, while large student models benefit more from large teachers.</strong>
    </p>
    <br>
    <figure class="image">
      <img src="static/images/main_2.jpg" alt="" />
    </figure>
    <br>
    <p>
      Large model CoT Gap (<span>&Delta;<sub>Large</sub>=P<sub>Large</sub> - P<sub>Small</sub></span>) of student models with different models sizes for (a) Qwen family (b) Llama family. For teacher models, <code>Qwen2.5-72B-Instruct</code> is chosen as the large teacher to generate responses, while <code>Qwen2.5-3B-Instruct</code> is chosen as the small teacher to generate responses. Negative (positive) <span>&Delta;<sub>Large</sub></span> indicates that large teacher CoT is worse (better) than small teacher CoT. Our results demonstrate that small teacher CoT is better for smaller student models (indicated by <span>&Delta;<sub>Large</sub></span> &lt; 0), while large model CoT is better for larger student models (indicated by <span>&Delta;<sub>Large</sub></span> &gt; 0).
    </p>
    <br>
    
    <p class="has-text-left"></p>
      <strong>Takeaway 3: Effect of Domain Knowledge. Limited domain knowledge of small models may hinder their learning from strong reasoning teachers.</strong>
    </p>
    <br>
    <figure class="image">
      <img src="static/images/math_expert.jpg" alt="" />
    </figure>
    <p>
      Math expert models usually have a less significant Learnability Gap than the general models. This indicates that the math expert model could more easily learn from long CoT data or large teacher CoT.
    </p>
    <br>

    <p class="has-text-left">
      <strong>Takeaway 4: Base vs Instruct. Small base models experience more significant learnability gap than Instruct models.</strong> 
    </p>
    <br>
    <figure class="image">
      <img src="static/images/base_vs_instruct.jpg" alt="" />
    </figure>
    <p>
      Base models generally exhibit a more significant learnability gap than Instruct models. This implies that it is more challenging for small base models to effectively learn from long CoT data or large teacher CoT.
    </p>
    <br>

  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Optional section title -->
    <div class="has-text-centered">
    <h2 class="title is-3">Mix Distillation</h2>
    </div>
    <br>
    <!-- Figure on top -->

    <p class="has-text-left"></p>
      <strong>Takeaway 5: Mix Distillation Bridges Gap. By mixing long CoT data (resp. large teacher CoTs) and short CoT data (resp. small teacher CoT), the small student model could achieve better performance compared to training on either data alone.</strong>
    </p>
    <br>
    <figure class="image">
      <img src="static/images/table.jpg" style="width: 100%; margin: 0 auto;" alt="" />
    </figure>
    <p class="has-text-left">
      
      <strong>Mix Distillation</strong> outperforms the baseline models across most metrics. We use <code>Llama3.2-3B-Instruct</code> and <code>Qwen2.5-3B-Instruct</code> as the student model and 7.5k samples in MATH dataset as the training set. We distill different teacher models to generate responses as the baseline. Our proposed Mix-Long combines long CoT data and normal CoT data in a 1:4 ratio, while Mix-Large combines strong model response and weak model response with the same proportion. Experimental results demonstrate that both Mix-Long and Mix-Large surpass baselines in most evaluation metrics. The highest score is bolded, and the second highest score is <u>underlined</u>.
      
    </p>
    <br>
  </div>
</section>





<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <p>
        If you find our work useful, please consider citing our paper:
      </p>
      <pre><code>
      @misc{li2025smallmodelsstrugglelearn,
        title={Small Models Struggle to Learn from Strong Reasoners}, 
        author={Yuetai Li and Xiang Yue and Zhangchen Xu and Fengqing Jiang and Luyao Niu and Bill Yuchen Lin and Bhaskar Ramasubramanian and Radha Poovendran},
        year={2025},
        eprint={2502.12143},
        archivePrefix={arXiv},
        primaryClass={cs.AI},
        url={https://arxiv.org/abs/2502.12143}, 
      }    
    </code></pre>
    </div>
</section>
<!--End BibTex citation -->

<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
